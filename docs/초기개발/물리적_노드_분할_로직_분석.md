# 물리적 노드 분할 로직 분석

## 문서 개요
이 문서는 대화 리스트를 노드로 변환하는 **물리적 메커니즘**을 정의합니다.
- **배경**: AI가 분기 시점을 판단하기 전에, 판단 결과를 **어떻게 코드로 구현할지** 정의 필요
- **목표**: 두 가지 접근 방식의 물리적 구현을 상세히 비교하여 최적 방법 선택

---

## 접근 방식 비교

### 방식 A: 턴 단위 즉시 노드 생성 (Turn-Instant Creation)

#### 핵심 개념
- **1턴 = 1노드** (사용자 질문 + AI 응답이 하나의 노드)
- 대화가 완료되는 **즉시** 노드 자동 생성
- 버퍼 없음 (또는 임시 버퍼만 존재)

#### 자료구조

```python
# 노드 구조
class Node:
    id: str                    # UUID
    parent_id: str | None      # 부모 노드 ID
    user_question: str         # 사용자 질문
    ai_answer: str             # AI 응답
    created_at: timestamp      # 생성 시각
    metadata: dict             # 추가 메타데이터

# 전역 상태
all_nodes: Dict[str, Node] = {}        # {node_id: Node}
checkpoints: Dict[str, str] = {}       # {checkpoint_name: node_id}
current_node_id: str | None = None     # 현재 활성 노드

# 임시 버퍼 (옵션)
temp_question: str | None = None       # 사용자가 입력 중인 질문
```

#### 물리적 동작 흐름

```python
def handle_user_input(user_input: str):
    """사용자 입력 처리"""

    # 1. 사용자 질문 임시 저장
    temp_question = user_input

    # 2. AI 응답 생성
    context = get_context_path(current_node_id)
    ai_response = call_llm_api(context + [{"role": "user", "content": user_input}])

    # 3. 즉시 노드 생성
    new_node = Node(
        id=generate_uuid(),
        parent_id=current_node_id,  # 현재 노드를 부모로 설정
        user_question=temp_question,
        ai_answer=ai_response,
        created_at=now(),
        metadata={}
    )

    # 4. 트리에 추가
    all_nodes[new_node.id] = new_node

    # 5. 현재 위치 업데이트
    current_node_id = new_node.id

    # 6. 임시 버퍼 비우기
    temp_question = None

    return ai_response


def get_context_path(target_node_id: str | None) -> List[Dict]:
    """노드 ID로부터 루트까지의 모든 대화 추출"""
    if target_node_id is None:
        return []

    path = []
    current = target_node_id

    # 역추적
    while current is not None:
        node = all_nodes[current]
        path.insert(0, node)  # 앞에 삽입 (시간 순서 유지)
        current = node.parent_id

    # LLM 포맷으로 변환
    messages = []
    for node in path:
        messages.append({"role": "user", "content": node.user_question})
        messages.append({"role": "assistant", "content": node.ai_answer})

    return messages


def goto_command(target_id: str):
    """특정 노드로 이동"""
    global current_node_id

    if target_id in all_nodes:
        current_node_id = target_id
        print(f"이동 완료: {target_id}")
    else:
        print("존재하지 않는 노드입니다")


def save_command(checkpoint_name: str):
    """/save 명령: 현재 노드에 이름표 붙이기"""
    if current_node_id is None:
        print("저장할 노드가 없습니다")
        return

    checkpoints[checkpoint_name] = current_node_id
    print(f"체크포인트 '{checkpoint_name}' 저장 완료")
```

#### 예시 시나리오

```
[사용자 행동]
1. 사용자: "오늘 날씨는?"
   → AI: "맑습니다"
   → node_1 자동 생성: {id: "a1", parent: None, Q: "오늘 날씨는?", A: "맑습니다"}
   → current_node_id = "a1"

2. 사용자: "내일은?"
   → AI: "비가 올 것 같습니다"
   → node_2 자동 생성: {id: "a2", parent: "a1", Q: "내일은?", A: "비가 올 것 같습니다"}
   → current_node_id = "a2"

3. 사용자: "/save weather_chat"
   → checkpoints["weather_chat"] = "a2"

4. 사용자: "/goto a1"
   → current_node_id = "a1"

5. 사용자: "여행 추천해줘"
   → AI: "제주도 어떠세요?"
   → node_3 자동 생성: {id: "a3", parent: "a1", Q: "여행 추천해줘", A: "제주도 어떠세요?"}
   → current_node_id = "a3"

[최종 트리 구조]
    node_1 (a1)
     |
     +-- node_2 (a2) ["weather_chat"]
     |
     +-- node_3 (a3)
```

---

### 방식 B: 분기 감지 시 노드 생성 (Branch-Detection Split)

#### 핵심 개념
- 대화가 **버퍼에 누적**됨
- 분기 시점 감지 시 **버퍼를 노드로 변환**
- **1노드 = 여러 턴** (messages 리스트)

#### 자료구조

```python
# 노드 구조
class Node:
    id: str                              # UUID
    parent_id: str | None                # 부모 노드 ID
    messages: List[Dict[str, str]]       # [{"role": "user", "content": "..."}, ...]
    created_at: timestamp                # 생성 시각
    metadata: dict                       # 추가 메타데이터

# 전역 상태
all_nodes: Dict[str, Node] = {}              # {node_id: Node}
checkpoints: Dict[str, str] = {}             # {checkpoint_name: node_id}
current_node_id: str | None = None           # 현재 활성 노드

# 버퍼 (핵심!)
current_buffer: List[Dict[str, str]] = []    # 현재 대화 버퍼
```

#### 물리적 동작 흐름

```python
def handle_user_input(user_input: str):
    """사용자 입력 처리"""

    # 1. 버퍼에 사용자 질문 추가
    current_buffer.append({"role": "user", "content": user_input})

    # 2. AI 응답 생성
    context = get_full_context()
    ai_response = call_llm_api(context)

    # 3. 버퍼에 AI 응답 추가
    current_buffer.append({"role": "assistant", "content": ai_response})

    # 4. 분기 감지 확인 (여기서는 명시적 명령 기준)
    # 아직 노드 생성하지 않음!

    return ai_response


def get_full_context() -> List[Dict]:
    """전체 컨텍스트 조회 (부모 경로 + 현재 버퍼)"""
    context = []

    # 부모 경로 추가
    if current_node_id is not None:
        parent_path = get_node_path(current_node_id)
        for node in parent_path:
            context.extend(node.messages)

    # 현재 버퍼 추가
    context.extend(current_buffer)

    return context


def get_node_path(target_node_id: str) -> List[Node]:
    """노드 ID로부터 루트까지의 경로"""
    path = []
    current = target_node_id

    while current is not None:
        node = all_nodes[current]
        path.insert(0, node)
        current = node.parent_id

    return path


def split_and_create_node():
    """
    분기 시점 감지 시 호출
    현재 버퍼를 노드로 변환
    """
    global current_node_id, current_buffer

    if len(current_buffer) == 0:
        print("버퍼가 비어있습니다")
        return

    # 새 노드 생성
    new_node = Node(
        id=generate_uuid(),
        parent_id=current_node_id,  # 현재 노드를 부모로
        messages=current_buffer.copy(),  # 버퍼 내용 복사
        created_at=now(),
        metadata={}
    )

    # 트리에 추가
    all_nodes[new_node.id] = new_node

    # 현재 위치 업데이트
    current_node_id = new_node.id

    # 버퍼 비우기
    current_buffer = []

    print(f"노드 생성 완료: {new_node.id}")


def goto_command(target_id: str):
    """
    /goto 명령: 분기 발생!
    1. 현재 버퍼를 노드로 저장
    2. 목표 노드로 이동
    """
    global current_node_id, current_buffer

    # 1. 버퍼에 내용이 있으면 먼저 저장
    if len(current_buffer) > 0:
        split_and_create_node()

    # 2. 이동
    if target_id in all_nodes:
        current_node_id = target_id
        current_buffer = []  # 버퍼 초기화
        print(f"이동 완료: {target_id}")
    else:
        print("존재하지 않는 노드입니다")


def save_command(checkpoint_name: str):
    """/save 명령: 분기 발생!"""
    global current_buffer

    # 1. 버퍼를 노드로 변환
    if len(current_buffer) > 0:
        split_and_create_node()

    # 2. 현재 노드에 이름표 붙이기
    if current_node_id is None:
        print("저장할 노드가 없습니다")
        return

    checkpoints[checkpoint_name] = current_node_id
    print(f"체크포인트 '{checkpoint_name}' 저장 완료")
```

#### 예시 시나리오

```
[사용자 행동]
1. 사용자: "오늘 날씨는?"
   → AI: "맑습니다"
   → current_buffer = [
       {"role": "user", "content": "오늘 날씨는?"},
       {"role": "assistant", "content": "맑습니다"}
     ]
   → 노드 생성 안 함!

2. 사용자: "내일은?"
   → AI: "비가 올 것 같습니다"
   → current_buffer = [
       {"role": "user", "content": "오늘 날씨는?"},
       {"role": "assistant", "content": "맑습니다"},
       {"role": "user", "content": "내일은?"},
       {"role": "assistant", "content": "비가 올 것 같습니다"}
     ]
   → 여전히 노드 생성 안 함!

3. 사용자: "/save weather_chat"
   → split_and_create_node() 호출
   → node_1 생성: {id: "a1", parent: None, messages: [...4개 메시지]}
   → checkpoints["weather_chat"] = "a1"
   → current_buffer = []

4. 사용자: "모레는?"
   → AI: "맑을 겁니다"
   → current_buffer = [
       {"role": "user", "content": "모레는?"},
       {"role": "assistant", "content": "맑을 겁니다"}
     ]

5. 사용자: "/goto a1"
   → split_and_create_node() 호출
   → node_2 생성: {id: "a2", parent: "a1", messages: [...2개 메시지]}
   → current_node_id = "a1"
   → current_buffer = []

6. 사용자: "여행 추천해줘"
   → AI: "제주도 어떠세요?"
   → current_buffer = [
       {"role": "user", "content": "여행 추천해줘"},
       {"role": "assistant", "content": "제주도 어떠세요?"}
     ]

7. 사용자: "/save travel_chat"
   → split_and_create_node() 호출
   → node_3 생성: {id: "a3", parent: "a1", messages: [...2개 메시지]}
   → checkpoints["travel_chat"] = "a3"

[최종 트리 구조]
    node_1 (a1) ["weather_chat"] - 4개 메시지
     |
     +-- node_2 (a2) - 2개 메시지
     |
     +-- node_3 (a3) ["travel_chat"] - 2개 메시지
```

---

## 상세 비교 분석

### 1. 메모리 사용량

| 항목 | 방식 A (턴 단위) | 방식 B (버퍼 기반) |
|------|-----------------|------------------|
| **노드 수** | 많음 (턴마다 생성) | 적음 (분기마다 생성) |
| **노드당 크기** | 작음 (Q+A 1쌍) | 큼 (messages 리스트) |
| **버퍼 크기** | 없음 (또는 1턴) | 가변적 (분기 전까지) |
| **예시** | 10턴 = 10노드 | 10턴 = 1~10노드 (분기 빈도에 따라) |

**분석**:
- 방식 A: 노드 수가 많지만 각 노드는 단순함
- 방식 B: 노드 수는 적지만 각 노드가 복잡함
- 실제 메모리: 대화 내용은 동일하므로 총 메모리 사용량 비슷
- **차이점**: 방식 B는 분기 전까지 버퍼에 누적 (메모리 일시 증가)

### 2. 구현 복잡도

#### 2.1 ID 생성 및 관리

**방식 A**:
```python
# 간단함 - 매 턴마다 UUID 생성
new_id = generate_uuid()
```

**방식 B**:
```python
# 복잡함 - 분기 감지 로직 필요
if should_split():  # 언제 split 할지 판단 로직 필요
    new_id = generate_uuid()
```

#### 2.2 parent_id 할당

**방식 A**:
```python
# 간단함 - 항상 current_node_id가 부모
parent_id = current_node_id
```

**방식 B**:
```python
# 동일하게 간단함
parent_id = current_node_id
```

#### 2.3 분기 처리

**방식 A**:
```python
# 자동 처리됨
# /goto B 후 새 질문 → 자동으로 B의 자식 노드 생성
```

**방식 B**:
```python
# 명시적 처리 필요
def goto_command(target):
    if len(current_buffer) > 0:
        split_and_create_node()  # 버퍼 저장 로직
    current_node_id = target
    current_buffer = []
```

**복잡도 점수**:
- 방식 A: ⭐⭐ (단순함)
- 방식 B: ⭐⭐⭐⭐ (버퍼 관리 + 분기 감지 로직)

### 3. 데이터 무결성

#### 3.1 분기 보존

**방식 A**:
```python
시나리오: A→B→C, /goto B, 새 대화 D

결과:
    A
    |
    B
    |
    +-- C  ✅ 자동 보존됨
    |
    +-- D  ✅ 자동 보존됨
```

**방식 B**:
```python
시나리오: A→B→C 대화 중 (버퍼에만 존재), /goto A

결과 (잘못 구현 시):
    A
    |
    B  ❌ C는 버퍼에만 있었으므로 손실 가능

올바른 구현:
    A
    |
    B
    |
    C  ✅ /goto 시 split_and_create_node() 호출하면 보존
```

**위험도**:
- 방식 A: ⭐ (자동 보존, 손실 위험 없음)
- 방식 B: ⭐⭐⭐⭐ (/goto 구현 시 버퍼 저장 로직 누락하면 데이터 손실)

#### 3.2 일관성

**방식 A**:
- 항상 일관된 상태 (all_nodes = 전체 대화 히스토리)
- 버퍼가 없으므로 "저장 안 된 대화" 개념 없음

**방식 B**:
- 일시적 불일치 (버퍼 ≠ all_nodes)
- "저장 안 된 대화"가 버퍼에 존재
- 시스템 충돌 시 버퍼 손실 위험

### 4. 확장성

#### 4.1 UI 전환 (터미널 → 웹)

**방식 A**:
```python
# 터미널
사용자 입력 → 노드 생성 → current_node_id 변경

# 웹 (동일 로직)
사용자 입력 → 노드 생성 → current_node_id 변경
노드 클릭 → current_node_id 변경만
```

**방식 B**:
```python
# 터미널
사용자 입력 → 버퍼 추가 → 분기 명령 시 노드 생성

# 웹 (추가 로직 필요)
노드 클릭 → 버퍼 저장 로직 필요
실시간 시각화 → 버퍼 내용도 표시해야 함 (트리에 없음)
```

**확장성 점수**:
- 방식 A: ⭐⭐⭐⭐⭐ (UI 독립적)
- 방식 B: ⭐⭐⭐ (버퍼 상태 관리 복잡)

#### 4.2 AI 판단 통합

**방식 A**:
```python
# AI가 "이 턴은 중요해!"라고 판단 → 이미 노드로 생성되어 있음
# AI가 할 수 있는 일: 노드에 메타데이터 추가

def ai_mark_important(node_id: str):
    all_nodes[node_id].metadata["important"] = True
```

**방식 B**:
```python
# AI가 "지금 split 해야 해!"라고 판단
def ai_should_split() -> bool:
    # 대화 패턴 분석
    if detect_topic_change(current_buffer):
        return True
    return False

# 메인 루프
if ai_should_split():
    split_and_create_node()
```

**AI 통합 관점**:
- 방식 A: AI는 이미 생성된 노드를 분석/라벨링
- 방식 B: AI가 split 시점을 능동적으로 결정

### 5. 성능

#### 5.1 노드 생성 빈도

| 시나리오 | 방식 A | 방식 B |
|---------|--------|--------|
| 10턴 대화, 분기 없음 | 10회 노드 생성 | 1회 노드 생성 (최종 /save 시) |
| 10턴 대화, 5번 분기 | 10회 노드 생성 | 5회 노드 생성 |

**성능 영향**:
- 노드 생성 자체는 O(1) 연산 (단순 딕셔너리 추가)
- 실제 성능 차이는 미미함 (UUID 생성 비용 낮음)

#### 5.2 컨텍스트 조회 성능

**방식 A**:
```python
def get_context_path(node_id):
    # 노드 수: N (깊이)
    # 시간 복잡도: O(N)
    # N = 대화 턴 수
```

**방식 B**:
```python
def get_full_context():
    # 노드 수: M (분기 수)
    # 버퍼 크기: K (미저장 턴 수)
    # 시간 복잡도: O(M + K)
    # M << N (분기가 턴보다 적음)
```

**성능 점수**:
- 방식 A: O(N) - N = 총 턴 수
- 방식 B: O(M) - M = 분기 수 (일반적으로 M < N)
- **하지만**: 실제 대화 깊이는 수십~수백 수준, 차이 미미

---

## 노드생성논의 문서와의 일치성 검토

### 노드생성논의 문서의 결론 (이전 논의)
```
최종 채택 방식: Model B (자동 노드 생성)
- 1턴 = 1노드
- 매 턴마다 자동으로 노드 생성
- /save는 "이름표 붙이기"
- /goto는 "위치 이동"
```

### 현재 분석과의 관계

**방식 A (턴 단위 즉시 생성)** = **노드생성논의의 최종 채택안**
- ✅ 동일: 1턴 = 1노드
- ✅ 동일: 자동 노드 생성
- ✅ 동일: /save = 이름표
- ✅ 동일: 버퍼 로직 최소화

**방식 B (버퍼 기반 분기 감지)** = **노드생성논의에서 폐기된 "Message Block 모델"**
- ❌ 문제: 버퍼 관리 복잡
- ❌ 문제: /goto 시 분기 손실 위험
- ❌ 문제: shelves 같은 추가 메커니즘 필요

---

## 최종 권고사항

### 권고: 방식 A (턴 단위 즉시 노드 생성) 채택

#### 이유

1. **단순성** ⭐⭐⭐⭐⭐
   - 버퍼 관리 불필요
   - 분기 감지 로직 불필요
   - 구현이 직관적

2. **데이터 무결성** ⭐⭐⭐⭐⭐
   - 모든 대화가 자동으로 트리에 기록
   - 분기 자동 보존
   - 데이터 손실 위험 없음

3. **확장성** ⭐⭐⭐⭐⭐
   - UI 전환 용이 (터미널 → 웹)
   - 노드 클릭 = ID 변경만
   - AI 통합 간단 (노드 메타데이터 활용)

4. **이전 논의와 일치**
   - "노드생성논의" 문서의 최종 채택안
   - 이미 검증된 접근 방식

#### AI 판단 통합 방안

**질문**: "방식 A를 쓰면 AI가 split 시점을 판단할 수 없지 않나?"

**답변**: **AI의 역할을 재정의**
```python
# 방식 A에서 AI의 역할
# "언제 split 할까?"가 아니라 "어떤 노드가 중요할까?"

def ai_analyze_conversation():
    """AI가 대화를 분석하여 중요 노드 표시"""
    for node in all_nodes.values():
        importance = ai_score_importance(node)
        if importance > threshold:
            node.metadata["important"] = True
            node.metadata["importance_score"] = importance

def ai_suggest_checkpoint():
    """AI가 체크포인트 추천"""
    important_nodes = [n for n in all_nodes.values() if n.metadata.get("important")]
    return important_nodes[-1].id  # 가장 최근 중요 노드
```

**방식 A + AI 판단 = "사후 분석"**
- 모든 턴이 노드로 생성됨
- AI는 생성된 노드들을 분석하여 중요도 판단
- 사용자에게 "이 시점을 체크포인트로 저장하시겠습니까?" 제안

**장점**:
- AI 판단 실패해도 데이터 무결성 유지
- 사용자가 최종 결정권 보유
- 나중에 AI 모델 개선 가능 (노드는 이미 저장되어 있음)

---

## 구현 우선순위

### Phase 1: 기본 방식 A 구현
```python
✅ 노드 자동 생성
✅ /save (체크포인트)
✅ /goto (이동)
✅ get_context_path (컨텍스트 조회)
```

### Phase 2: AI 사후 분석 추가
```python
✅ ai_analyze_conversation (중요도 분석)
✅ ai_suggest_checkpoint (체크포인트 추천)
✅ 노드 메타데이터 UI 표시
```

### Phase 3: 고급 기능
```python
✅ 병합 기능 (LCA 활용)
✅ 자동 shelves (버려진 분기 자동 보관)
✅ 대화 패턴 분석
```

---

## 결론

**물리적 노드 분할 로직 = 방식 A (턴 단위 즉시 생성)**

**핵심 원칙**:
1. 매 턴마다 자동으로 노드 생성
2. 버퍼 로직 최소화 (임시 저장만)
3. 분기는 자연스럽게 발생 (parent_id 변경)
4. AI는 생성된 노드를 분석하여 중요도 판단

**다음 단계**:
- ✅ 물리적 로직 정의 완료
- ⏭️ Phase CLI-1 구현 시작 (터미널 프로토타입)
- ⏭️ AI 중요도 분석 알고리즘 설계 (Phase 2)
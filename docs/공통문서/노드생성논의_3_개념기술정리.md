# 노드생성 논의 - 개념·주제·기술 정리 및 의문점

## 문서 개요
이 문서는 논의 과정에서 등장한 **기술적 개념**, **설계 주제**, **알고리즘**, 그리고 **남아있는 의문점**들을 체계적으로 정리합니다.

---

## 1부: 핵심 개념 정리

### 1.1 트리 구조 (Tree Structure)

**정의**
```
트리 = 계층 구조의 데이터 조직 방식
- 루트(root): 시작점 (부모 없음)
- 노드(node): 각 대화 턴
- 간선(edge): parentId로 표현
- 자식(child): 특정 노드에서 시작한 분기
```

**논의 문맥에서의 의미**
- 대화 히스토리를 선형이 아닌 **분기 구조**로 저장
- "A→B→C" 경로와 "A→B→D" 경로를 동시에 보존
- 각 경로는 서로 다른 자식 노드들로 표현됨

**코드 표현**
```python
노드 = {
    "id": "node_1",
    "parentId": "root",  # 부모 노드 지정
    "user_question": "...",
    "ai_answer": "..."
}

부모-자식 관계:
root의 자식: [node_A]
node_A의 자식: [node_B, node_C]
           (B와 C는 A에서 분기된 경로)
```

---

### 1.2 활성 경로 (Active Path)

**정의**
```
현재 대화의 "맥락"이 되는 경로
= root에서 현재 노드까지의 선형 경로
```

**예시**
```
트리 구조:
        root
         |
      node_A
       /    \
    node_B  node_C
      |
    node_D

활성 경로가 node_D일 때:
  root → node_A → node_B → node_D
  
이 경로의 모든 Q+A를 AI에 전달해야 함
```

**구현**
```python
def get_context_path(target_node_id):
    """현재 노드에서 root까지 역추적"""
    path = []
    current_id = target_node_id
    while current_id:
        node = get_node(current_id)
        path.append(node)
        current_id = node["parentId"]
    return list(reversed(path))  # root가 첫 번째
```

---

### 1.3 경로 전환 (Path Switching)

**정의**
```
사용자가 특정 체크포인트로 이동했을 때,
활성 경로를 그 시점의 경로로 변경
```

**동작**
```
AS-IS (선형 대화):
  A → B → C → 막힘 → 다시 A? 불가능

TO-BE (트리 구조):
  1. A → B → C (경로 1)
  2. /goto A
  3. A → D (경로 2)
  
  → A 노드 이후로 경로가 분기됨
```

**중요 성질**
- 경로 전환 후 버려진 경로(C)는 **삭제되지 않고 보존**
- 나중에 언제든 다시 방문 가능
- 파일 시스템의 "폴더 이동"과 동일한 개념

---

### 1.4 체크포인트 (Checkpoint)

**정의**
```
사용자가 "이 시점을 기억해둬"라고 표시한 노드
= checkpoints 딕셔너리의 이름 정보
```

**구조**
```python
checkpoints = {
    "A": "node_id_A",
    "B": "node_id_B",
    "중간": "node_id_X"
}

# /save A 실행 시:
checkpoints["A"] = current_node_id

# /goto A 실행 시:
current_node_id = checkpoints["A"]
```

**비유**
- Git: 커밋에 태그 달기 (`git tag`)
- 북마크: 웹사이트 즐겨찾기
- 파일시스템: 바로가기/심볼릭 링크

---

### 1.5 대화 턴 (Conversation Turn)

**정의**
```
사용자 질문 + AI 응답 = 1 턴
= 1 노드
```

**왜 이 정의가 중요한가?**
1. **의미적 완전성**: 질문 없는 응답 불가능
2. **LLM 컨텍스트**: "role: user" 다음에는 항상 "role: assistant"
3. **분기 관리**: 턴이 끝난 시점부터 새로운 분기 가능

**구조**
```python
노드 = {
    "id": uuid,
    "parentId": 부모_노드_id,
    "user_question": "사용자 입력",
    "ai_answer": "AI 응답"
}
```

---

### 1.6 자동 노드 생성 (Auto Node Generation)

**정의**
```
사용자가 질문을 하고 AI가 응답할 때마다,
자동으로 새 노드를 생성하고 all_nodes에 추가
```

**동작 흐름**
```python
1. 사용자 입력 받기
2. AI 응답 생성
3. 새 노드 생성:
   {
       "id": uuid(),
       "parentId": current_node_id,
       "user_question": 입력,
       "ai_answer": 응답
   }
4. all_nodes에 추가
5. current_node_id = 새 노드의 id
```

**이점**
- 버퍼 로직 불필요 ✅
- 모든 분기 자동 보존 ✅
- `/goto` 시 복잡한 저장 로직 불필요 ✅

---

## 2부: 설계 주제 및 선택 기록

### 2.1 주제: "노드의 최소 단위는 무엇인가?"

**후보 1: Role 기반 (Model A - 탈락)**
```
노드 = 1 메시지 (user 또는 ai)
문제: role 분리 시 복구 버그 발생
```

**후보 2: 메시지 블록 (Message Block - 탈락)**
```
노드 = 여러 턴의 묶음 (messages_list)
문제: 블록 내부 분기 시 노드 분할 필요 → 복잡
```

**최종 선택: 대화 턴 (Model B - 채택) ✅**
```
노드 = 1 턴 (user_question + ai_answer)
장점: 간단하고 분기 자동 보존
```

---

### 2.2 주제: "저장의 역할 재정의"

**초기 개념**
```
/save checkpoint_name
  → 현재까지의 대화를 버퍼에서 노드로 변환
  → 해당 노드를 checkpoints에 등록
```

**문제점**
- 저장과 이름표가 혼합됨
- 버퍼 관리 복잡
- 분기 손실 위험

**최종 개념**
```
/save checkpoint_name
  → (저장은 이미 자동으로 됨)
  → 현재 노드에 이름표만 붙이기
  → checkpoints[name] = current_node_id
```

**변화**
| 항목 | 초기 | 최종 |
|------|------|------|
| 저장 시점 | /save 시 | 매 턴 자동 |
| /save 역할 | 저장 + 이름표 | 이름표만 |
| 버퍼 필요 | Yes | No |

---

### 2.3 주제: "분기 보존의 자동화"

**초기 접근**
```
/goto 실행 시:
  - 현재 버퍼를 shelves에 임시 저장
  - 나중에 /restore로 복구
```

**문제**
- shelves는 트리 구조가 아님
- 임시 저장일 뿐 영구 보존 아님
- A→B→C, A→B→D 같은 복수 분기 처리 곤란

**최종 접근**
```
매 턴마다 자동으로 노드 생성
  → 모든 분기가 자동으로 all_nodes 트리에 저장
  → /goto는 단순히 current_node_id만 변경
  → shelves 로직 완전 제거
```

---

## 3부: 핵심 알고리즘

### 3.1 경로 역추적 알고리즘 (Path Backtracking)

**목적**
```
특정 노드에서 root까지의 경로를 찾기
→ AI에 전달할 전체 맥락 생성
```

**구현**
```python
def get_context_path(target_node_id):
    """
    target_node_id에서 root까지 parentId를 따라 역추적
    반환: root부터 target까지의 노드 리스트 (시간순)
    """
    path = []
    current_id = target_node_id
    
    while current_id is not None:
        node = get_node(current_id)
        if node:
            path.append(node)
            current_id = node["parentId"]
        else:
            break
    
    return list(reversed(path))  # root가 인덱스 0
```

**시간복잡도**: O(H) where H = 트리의 높이
**공간복잡도**: O(H)

**예시**
```
트리:
  root
   |
node_A
   |
node_B
   |
node_C

get_context_path("node_C"):
  1. node_C 찾기
  2. node_C.parentId = node_B
  3. node_B 찾기
  4. node_B.parentId = node_A
  5. node_A 찾기
  6. node_A.parentId = root
  7. root 찾기
  8. root.parentId = None → 종료
  
반환: [root, node_A, node_B, node_C]
```

---

### 3.2 맥락 생성 알고리즘 (Context Generation)

**목적**
```
노드 리스트를 AI가 이해할 수 있는 메시지 리스트로 변환
```

**구현**
```python
def generate_ai_context(path_nodes):
    """
    경로의 모든 노드를 LLM API 호출 형식으로 변환
    반환: [{"role": "user", "content": "..."}, ...]
    """
    messages = []
    for node in path_nodes:
        if node.get("user_question"):
            messages.append({
                "role": "user",
                "content": node["user_question"]
            })
        if node.get("ai_answer"):
            messages.append({
                "role": "assistant",
                "content": node["ai_answer"]
            })
    return messages
```

**사용 예시**
```python
# 현재 노드: node_C
path_nodes = get_context_path("node_C")
# 반환: [root, node_A, node_B, node_C]

context = generate_ai_context(path_nodes)
# 반환: [
#   {"role": "assistant", "content": "root의 답변"},
#   {"role": "user", "content": "질문 A"},
#   {"role": "assistant", "content": "답변 A"},
#   {"role": "user", "content": "질문 B"},
#   {"role": "assistant", "content": "답변 B"},
#   {"role": "user", "content": "질문 C"},
#   {"role": "assistant", "content": "답변 C"}
# ]

# 이 context를 OpenAI API 등에 전달
response = openai.ChatCompletion.create(
    messages=context,
    model="gpt-4"
)
```

---

### 3.3 턴 생성 및 저장 알고리즘

**대화 턴 처리 흐름**
```python
while True:
    user_input = input(f"[{current_node_id}] > ")
    
    # 1. 활성 경로의 맥락 생성
    path_nodes = get_context_path(current_node_id)
    context_messages = generate_ai_context(path_nodes)
    
    # 2. 사용자 입력을 맥락에 추가
    context_messages.append({"role": "user", "content": user_input})
    
    # 3. AI 응답 생성
    ai_response = call_llm_api(context_messages)
    
    # 4. 새 노드 자동 생성
    new_node = {
        "id": str(uuid.uuid4()),
        "parentId": current_node_id,  # 현재 위치를 부모로 설정
        "user_question": user_input,
        "ai_answer": ai_response
    }
    all_nodes.append(new_node)
    
    # 5. 현재 위치 업데이트
    current_node_id = new_node["id"]
    
    # 6. AI 응답 출력
    print(f"🤖 {ai_response}")
```

---

### 3.4 경로 전환 알고리즘

**명령어: `/goto checkpoint_name`**
```python
if user_input.startswith("/goto"):
    checkpoint_name = user_input.split()[1]
    
    if checkpoint_name in checkpoints:
        target_node_id = checkpoints[checkpoint_name]
        
        # 1. 활성 경로 교체
        current_node_id = target_node_id
        
        # 2. 이동한 지점의 맥락 표시
        path_nodes = get_context_path(current_node_id)
        context = generate_ai_context(path_nodes)
        
        print(f"🔄 '{checkpoint_name}'으로 이동했습니다.")
        print("--- 현재 대화 맥락 ---")
        for msg in context:
            print(f"  [{msg['role']}] {msg['content']}")
        print("---------------------")
```

**핵심**
- ✅ 버퍼 관리 없음
- ✅ 이전 경로는 all_nodes에 보존됨
- ✅ 새로운 대화 즉시 가능

---

### 3.5 체크포인트 등록 알고리즘

**명령어: `/save checkpoint_name`**
```python
if user_input.startswith("/save"):
    checkpoint_name = user_input.split()[1]
    
    # 현재 노드에 이름표 붙이기
    checkpoints[checkpoint_name] = current_node_id
    
    print(f"✅ '{checkpoint_name}' 체크포인트 등록 완료")
    print(f"   위치: {current_node_id}")
```

**역할**
- 저장 아님 (이미 자동으로 됨)
- 단순히 현재 노드에 이름 지정
- checkpoints 딕셔너리에 등록

---

## 4부: 남아있는 의문점 및 고려사항

### 4.1 의문: "UI에서는 어떻게 구현하나?"

**터미널**: node ID로 `/goto` 사용
**웹 UI**: 노드를 클릭 → 자동으로 해당 노드의 ID로 `/goto` 실행

**궁금증**
- 웹에서 트리를 시각화하려면?
- 노드가 수천 개일 때 성능은?
- 폴드/언폴드 기능은?

**고려사항**
- D3.js 같은 그래프 라이브러리 필요
- 네이티브 트리 렌더링 필요
- 깊이 제한 또는 가상 스크롤 필요

---

### 4.2 의문: "노드 ID를 사람이 기억할 수 있나?"

**현재**: UUID (너무 길음)

**개선 방안**
1. **짧은 ID 생성**: nanoid 같은 라이브러리 사용
2. **자동 이름 생성**: 첫 질문의 키워드로 체크포인트 자동 생성
3. **번호 체계**: A-1, A-2, A-3 등 계층적 번호

**예시**
```
현재: /goto 550e8400-e29b-41d4-a716-446655440000
개선: /goto abc123
더 좋음: /goto 날씨-확인
```

---

### 4.3 의문: "LCA(최저 공통 조상) 알고리즘의 필요성?"

**LCA란?**
```
두 노드의 가장 가까운 공통 부모를 찾는 알고리즘
```

**사용 사례**
```
트리:
        root
         |
      node_A
       /    \
    node_B  node_C
      |
    node_D

node_B와 node_C의 LCA = node_A
node_B와 node_D의 LCA = node_A
```

**왜 필요할 수 있나?**
- "두 경로 사이의 공통점을 찾기"
- "경로 비교" (두 대화가 얼마나 다른지)
- "병합" (두 경로를 합치기)

**현재 설계에서 필수?**
- ❌ 아님 (단순한 경로 저장만 필요)
- ✅ 나중에 고급 기능을 위해 고려 가능

---

### 4.4 의문: "데이터 크기 제한이 있나?"

**고려 사항**

| 항목 | 제한 | 영향 |
|------|------|------|
| 노드 수 | 수십만 개 | 메모리 O(N) |
| 트리 깊이 | 수백 ~ 수천 | 경로 역추적 O(H) |
| 메시지 길이 | 수만 토큰 | LLM API 토큰 제한 |

**최적화 방안**
- 오래된 노드 압축/아카이빙
- 페이지네이션 (100개 노드씩 로드)
- 메시지 요약 기능

---

### 4.5 의문: "멀티 사용자는 어떻게 처리하나?"

**문제**
```
현재: single user, single conversation

필요: multi user, multi session
```

**설계 변경**
```python
# Before
all_nodes = [...]
current_node_id = ...

# After
sessions = {
    "user_1": {
        "all_nodes": [...],
        "current_node_id": ...,
        "checkpoints": {...}
    },
    "user_2": {
        "all_nodes": [...],
        "current_node_id": ...,
        "checkpoints": {...}
    }
}
```

**데이터베이스 설계**
```
Collections:
- users
- sessions
- nodes (session_id, user_id 포함)
- checkpoints (session_id, user_id 포함)
```

---

### 4.6 의문: "버전 관리는 어떻게?"

**현재**: 모든 분기 보존 ✅
**향후 고려**: 버전 태깅

**예시**
```
version_1 = node_A ← 첫 번째 결론
version_2 = node_C ← 두 번째 시도
version_3 = node_E ← 최종 버전

checkpoints:
  "v1": node_A
  "v2": node_C
  "v3": node_E
```

---

### 4.7 의문: "Context Window 초과 시 어떻게?"

**문제**
```
LLM의 최대 토큰 제한 (예: GPT-4의 128K 토큰)
매우 깊은 대화 트리면 context 초과 가능
```

**해결책**
1. **최근 N개 턴만 포함**: sliding window
2. **요약**: 오래된 대화 요약본만 포함
3. **계층적 요약**: 트리 노드를 상위 노드로 압축

**구현 예시**
```python
def get_limited_context(target_node_id, max_tokens=100000):
    """
    경로를 거슬러 올라가며 토큰 카운트
    max_tokens 초과 시 중단
    """
    path_nodes = get_context_path(target_node_id)
    messages = []
    token_count = 0
    
    # 최근 노드부터 역순으로 추가
    for node in reversed(path_nodes):
        node_tokens = count_tokens(node)
        if token_count + node_tokens > max_tokens:
            # 요약본 추가
            messages.insert(0, summarize_node(node))
            break
        else:
            messages.extend(generate_ai_context([node]))
            token_count += node_tokens
    
    return messages
```

---

## 5부: 용어 정의 참고표

| 용어 | 의미 | 예시 |
|------|------|------|
| **노드** | 1 대화 턴 (Q+A) | user_q + ai_a = 1노드 |
| **간선** | 부모-자식 관계 | parentId로 표현 |
| **경로** | root부터 특정 노드까지 | [root, A, B, C] |
| **분기** | 같은 부모에서 나간 자식들 | A의 자식 [B, D] |
| **활성 경로** | 현재 대화의 맥락 | current_node_id에서 root까지 |
| **체크포인트** | 사용자가 지정한 이름 노드 | /save로 등록 |
| **이름 없는 노드** | checkpoints 미등록 노드 | 자동 생성되는 분기 |
| **LLM 컨텍스트** | AI에 전달되는 메시지 | generate_ai_context() 결과 |

---

## 최종 정리

**이 논의를 통해 얻은 결론**
1. ✅ 1턴 = 1노드 구조 채택
2. ✅ 자동 노드 생성으로 버퍼 로직 제거
3. ✅ /save = 이름표, /goto = 이동으로 명확화
4. ✅ 모든 분기 자동 보존
5. ✅ 간단한 알고리즘으로 복잡한 기능 구현

**남은 과제**
- [ ] 파이썬 프로토타입 구현
- [ ] 웹 UI 트리 시각화
- [ ] 성능 테스트 (대규모 데이터)
- [ ] LLM 실제 통합
- [ ] 멀티 사용자 지원
- [ ] Context window 관리

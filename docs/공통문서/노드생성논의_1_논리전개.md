# 노드생성 논의 - 논리 전개 정리

## 문서 개요
이 문서는 "트리 구조 AI 상담 챗봇" 설계를 위한 핵심 알고리즘 논의 과정을 정리한 것입니다.
- **시작점**: Plan.md 설계서 기반 AI 고민상담 대화 시스템
- **목표**: 터미널에서 파이썬 프로토타입으로 구현 가능한 알고리즘 설계
- **핵심**: 대화 분기를 보존하면서 언제든지 과거 시점으로 돌아가 새로운 대화 시작 가능

---

## 논리 전개 흐름

### 1단계: 문제 정의 (왜 이 시스템이 필요한가?)
**배경 문제**
- 기존 챗봇: 대화가 일렬로 진행되므로, 잘못된 이해가 발생하면 돌아가기 어려움
- 사용자 경험: 특정 지점으로 돌아가서 다른 방향으로 다시 시작하고 싶으나, 이전 대화는 보존되고 싶음

**해결 방안**
- 트리 구조: 모든 대화를 트리 노드로 저장
- 경로 전환: 과거의 어느 시점이든 클릭해서 그곳으로 돌아간 후, 새로운 대화 시작 가능
- 분기 보존: 버려진 대화 가지들은 삭제되지 않고 보존

---

### 2단계: 초기 모델 제안 (Model A - 낙제)

**Model A의 설계**
```
노드 구조:
- id: 고유 식별자
- parentId: 부모 노드
- role: "user" 또는 "ai"  ← 역할 분리
- content: 대화 내용
```

**이 모델의 문제점**
- `role` 구분: 사용자 질문과 AI 응답을 각각 다른 노드로 생성
- 복구 시 문제: 사용자가 "질문 노드"로 돌아가면, 다음 입력도 "질문"이 되어 **연속된 2개의 질문이 발생** → 버그 발생

**결론**: 이 방식은 "질문→응답" 쌍의 논리를 깨뜨림

---

### 3단계: 개선안 제안 (Model B - 채택)

**문제점 발견**
- 사용자의 지적: "질문 1개 + AI 응답 1개"를 하나의 "턴(Turn)"으로 봐야 함
- 이유: 이 "턴" 전체가 LLM API에 전달되는 최소 단위이며, 이 시점으로 돌아가면 자연스럽게 다음 질문을 할 수 있음

**Model B의 설계**
```
노드 구조:
- id: 고유 식별자
- parentId: 부모 노드
- user_question: 사용자 질문
- ai_answer: AI 응답
```

**장점**
- ✅ 질문과 응답이 함께 하나의 노드 (1턴 = 1노드)
- ✅ 이 노드로 돌아가면, 자연스럽게 새로운 질문 입력 가능
- ✅ 트리 구조가 명확함

**초기 우려사항**
- "사용자가 여러 턴을 말하다가 체크포인트를 만들면, 그 사이의 대화는 어떻게 되나?"

---

### 4단계: 블록 모델 논의 (중간 모델 - 재검토)

**사용자의 재질문**
- "하나의 노드가 여러 대화의 묶음(리스트)이 되어야 한다"
- "체크포인트 A에서 B까지의 모든 대화가 하나의 노드"
- "LLM API는 messages 리스트 전체를 받으므로, 노드 자체가 이 리스트의 '블록'이 되어야 함"

**Message Block 모델의 설계**
```
노드 구조:
- id: 고유 식별자
- parentId: 부모 노드
- messages_list: [
    {"role": "user", "content": "..."},
    {"role": "assistant", "content": "..."},
    ...
  ]
```

**상태 관리**
- `current_node_id`: 현재 대화가 붙어있는 노드 (마지막 체크포인트)
- `current_messages_buffer`: 아직 저장 안 된 실시간 대화 버퍼

**운영 방식**
- 사용자가 일반 대화 → `current_messages_buffer`에 쌓임
- 사용자가 `/save`(체크포인트) → 버퍼 내용으로 새 노드 생성
- 사용자가 `/goto` → 다른 노드로 이동, 버퍼는 날림 (이 부분이 문제가 됨)

**이 모델의 문제점**
- `/goto` 시 버퍼가 날아감
- A→B→C, A→B→D 분기 시, C와 D 중 하나는 트리에 저장 안 됨

---

### 5단계: 첫 번째 버퍼 보존 시도 (shelves 모델 - 폐기)

**문제 해결 시도**
- `/goto`할 때 버퍼를 삭제하지 말고, `shelves` 딕셔너리에 보관
- 돌아왔을 때 `/restore`로 복구

**문제점**
- 너무 복잡함
- shelves에만 저장되고, 트리 구조에는 반영 안 됨
- 결국 "A→B→C" 경로가 완전히 보존되지 않음

**결론**: 이 방식은 근본적인 해결이 아님

---

### 6단계: 최종 해결안 (자동 노드 생성 모델 - 채택!)

**핵심 아이디어**
- **모든 질문/응답 대화 후 자동으로 노드 생성** (버퍼를 기다리지 않음)
- `/save`는 "저장"이 아니라 **이미 생성된 노드에 '이름표' 붙이기** (즐겨찾기)
- `/goto`는 **단순히 현재 위치 변경** (자동 저장 같은 복잡한 로직 불필요)

**최종 노드 구조**
```
노드 (1턴 = 1노드):
- id: 고유 식별자
- parentId: 부모 노드
- user_question: 사용자 질문
- ai_answer: AI 응답
```

**운영 규칙**
1. 사용자가 질문 입력 → AI 응답 생성 → **즉시 새 노드 자동 생성 및 트리에 추가**
2. 사용자가 `/save A` → 현재 노드(node_id)에 "A"라는 이름 붙임 (`checkpoints["A"] = current_node_id`)
3. 사용자가 `/goto A` → `current_node_id` 값만 변경 (복잡한 버퍼 로직 없음)

**최종 트리 구조 예시**
```
A→B→C, A→B→D 분기 시나리오:

1. A 턴 완료 → node_A 자동 생성
2. B 턴 완료 → node_B 자동 생성 (node_A 자식)
3. /save B_point (node_B에 이름 붙임)
4. C 턴 완료 → node_C 자동 생성 (node_B 자식)
5. /goto B_point (현재 위치를 node_B로 변경)
6. D 턴 완료 → node_D 자동 생성 (node_B 자식)

최종 트리:
    root
     |
   node_A
     |
   node_B ("B_point" 이름표)
     |
   +-- node_C  ← A→B→C 분기 보존 ✅
   |
   +-- node_D  ← A→B→D 분기 보존 ✅
```

**이 방식의 우수성**
- ✅ 모든 대화가 자동으로 트리에 기록 (데이터 유실 없음)
- ✅ 분기 구조가 자연스럽고 직관적
- ✅ `/save`와 `/goto`가 간단함
- ✅ LLM API 호출 시 `get_context_path()`로 root부터 현재 노드까지의 모든 메시지 리스트 조회 가능

---

## 주요 알고리즘

### `get_context_path(target_node_id)`
- **역할**: 특정 노드에서 root까지의 경로 추적
- **동작**: parentId를 따라 계속 거슬러 올라감
- **반환**: root부터 target까지의 노드 리스트 (시간순)

### `generate_ai_context(path_nodes)`
- **역할**: 경로 노드들을 AI가 이해할 수 있는 메시지 리스트로 변환
- **동작**: 각 노드의 user_question과 ai_answer를 {"role": "user/assistant", "content": "..."} 형태로 추출
- **반환**: LLM API에 전달 가능한 메시지 리스트

### 대화 턴 처리
```
1. 사용자 입력 → AI 응답 생성
2. 새 노드 생성: 
   - id: uuid
   - parentId: current_node_id
   - user_question: 입력
   - ai_answer: 응답
3. all_nodes에 추가
4. current_node_id ← 새 노드의 id
```

---

## 결론
이 논의 과정은 **"어떤 자료구조와 운영 규칙이 트리 구조의 특성을 가장 잘 보존하면서도 구현이 간단한가"**를 찾아가는 과정이었습니다.

최종 답안:
- **1턴(질문+응답) = 1노드**
- **모든 턴은 자동으로 노드 생성**
- **`/save`는 "이름표 붙이기", `/goto`는 "위치 이동"**

이 방식이 가장 깔끔하고, 파일 시스템의 폴더 개념과도 일치합니다.

# 기술스택 선택근거
- 작성일: 2025-11-05
- 설계자: 아키텍처 설계자
- 상태: 확정
- 버전: 1.0

## 1. 기술 스택 개요

| 레이어 | 기술 | 버전 | 선택 근거 |
|--------|------|------|----------|
| **프론트엔드** | HTML/CSS/JavaScript | ES6+ | 프로토타입 빠른 구현, 프레임워크 없이 알고리즘 검증 |
| **백엔드** | Python + FastAPI | 3.10+ / 0.100+ | AI 라이브러리 풍부, 비동기 지원, 빠른 프로토타이핑 |
| **데이터베이스** | MongoDB | 6.0+ | 스키마 유연성, 트리 구조 자연스러운 표현, 수평 확장 |
| **캐시** | Redis | 7.0+ | 경로 캐싱, LCA 결과 캐싱, 세션 관리 |
| **AI 통합** | OpenAI API | GPT-4 | 품질 높은 응답, 안정적 서비스, 풍부한 문서 |
| **컨테이너** | Docker + Docker Compose | 24.0+ | 환경 일관성, 로컬 개발 편의성 |
| **CI/CD** | GitHub Actions | - | 무료, GitHub 통합, 간편한 설정 |

## 2. 프론트엔드 기술 선택

### 2.1 HTML/CSS/JavaScript (Vanilla JS)

#### 선택 이유
1. **알고리즘 검증 우선**: 트리 구조, 경로 전환, LCA 계산 등 핵심 알고리즘을 먼저 검증
2. **프레임워크 학습 시간 절약**: React/Vue 학습 없이 빠른 프로토타입 구현
3. **명확한 데이터 흐름**: 프레임워크 추상화 없이 상태 관리 로직 명확화
4. **향후 마이그레이션 용이**: 알고리즘 검증 후 React/Vue로 전환 가능

#### 대안 비교

| 기술 | 장점 | 단점 | 결정 |
|------|------|------|------|
| **Vanilla JS** | 학습 불필요, 빠른 구현, 알고리즘 명확 | 대규모 앱에 불리, 상태 관리 복잡 | ✅ **선택** (MVP) |
| **React** | 컴포넌트 재사용, 풍부한 생태계, 상태 관리 라이브러리 | 학습 곡선, 초기 설정 시간 | ⏭ 2단계 고려 |
| **Vue** | 쉬운 학습, 간결한 문법, 양방향 바인딩 | React보다 생태계 작음 | ⏭ 2단계 고려 |
| **Svelte** | 빠른 성능, 적은 코드량, 컴파일러 기반 | 생태계 작음, 레퍼런스 부족 | ❌ 제외 |

#### 트레이드오프
- **얻은 것**: 빠른 프로토타이핑, 알고리즘 검증 시간 단축
- **포기한 것**: 컴포넌트 재사용성, 대규모 앱 확장성
- **완화 전략**: 알고리즘 검증 후 React로 점진적 전환

### 2.2 상태 관리: 커스텀 StateManager

#### 선택 이유
1. **옵저버 패턴**: 간단한 pub-sub 패턴으로 충분
2. **Redux/MobX 불필요**: MVP 단계에서 과도한 추상화 방지
3. **학습 비용 제로**: 기본 JS 패턴만 사용

#### 구현 방식
```javascript
class StateManager {
  constructor() {
    this.state = { activePath: [], selectedNode: null };
    this.listeners = [];
  }
  subscribe(listener) { this.listeners.push(listener); }
  setState(newState) {
    this.state = { ...this.state, ...newState };
    this.listeners.forEach(l => l(this.state));
  }
}
```

## 3. 백엔드 기술 선택

### 3.1 Python 3.10+

#### 선택 이유
1. **AI 생태계**: OpenAI SDK, LangChain, Transformers 등 풍부
2. **빠른 프로토타이핑**: 동적 타이핑, 간결한 문법
3. **비동기 지원**: asyncio, async/await
4. **타입 힌트**: Python 3.10+ type hints로 정적 검증 가능

#### 대안 비교

| 언어 | 장점 | 단점 | 결정 |
|------|------|------|------|
| **Python** | AI 라이브러리 풍부, 빠른 개발, 비동기 지원 | 성능 (C++/Rust 대비), GIL 제약 | ✅ **선택** |
| **Node.js** | 프론트와 언어 통일, 비동기 기본, npm 생태계 | AI 라이브러리 부족, 타입 안정성 약함 | ❌ 제외 |
| **Java/Spring** | 엔터프라이즈 검증, 타입 안전, 성능 | 개발 속도 느림, 보일러플레이트 많음 | ❌ 제외 |
| **Go** | 빠른 성능, 동시성 우수, 간결 | AI 라이브러리 부족, 에러 핸들링 번거로움 | ❌ 제외 |
| **Rust** | 최고 성능, 메모리 안전, 동시성 | 학습 곡선 가파름, 개발 속도 느림 | ❌ 제외 |

#### 트레이드오프
- **얻은 것**: AI 통합 용이성, 빠른 개발 속도
- **포기한 것**: C++/Rust 수준 성능
- **완화 전략**: 성능 병목은 Cython/Rust 확장 모듈로 해결

### 3.2 FastAPI

#### 선택 이유
1. **비동기 네이티브**: async/await 완벽 지원
2. **자동 문서화**: OpenAPI/Swagger 자동 생성
3. **타입 검증**: Pydantic으로 요청/응답 검증
4. **빠른 성능**: Starlette 기반, Node.js/Go 수준
5. **개발 편의성**: 의존성 주입, 자동 리로드

#### 대안 비교

| 프레임워크 | 장점 | 단점 | 결정 |
|-----------|------|------|------|
| **FastAPI** | 비동기, 타입 힌트, 자동 문서화, 빠름 | 비교적 최신(2018), 생태계 성장 중 | ✅ **선택** |
| **Django** | 성숙한 생태계, ORM, Admin 패널 | 동기 기반(비동기 제한적), 무겁고 복잡 | ❌ 제외 |
| **Flask** | 가볍고 유연, 큰 생태계 | 비동기 약함, 타입 검증 수동, 문서화 수동 | ❌ 제외 |
| **Tornado** | 비동기 강점, WebSocket 지원 | 프레임워크 낡음, 문서 부족 | ❌ 제외 |

#### 코드 예시
```python
from fastapi import FastAPI, Depends
from pydantic import BaseModel

app = FastAPI()

class PathSwitchRequest(BaseModel):
    currentLeafId: str
    targetNodeId: str

@app.post("/switch")
async def switch_path(req: PathSwitchRequest, service: PathSwitchService = Depends()):
    result = await service.switch(req.currentLeafId, req.targetNodeId)
    return result
```

## 4. 데이터베이스 기술 선택

### 4.1 MongoDB

#### 선택 이유
1. **스키마 유연성**: 노드 메타 필드 확장 용이
2. **문서 지향**: 트리 노드를 자연스럽게 표현
3. **인덱스 성능**: 복합 인덱스로 경로 조회 최적화
4. **수평 확장**: 샤딩 지원
5. **개발 편의성**: 동적 스키마, 복잡한 마이그레이션 불필요

#### 대안 비교

| 데이터베이스 | 장점 | 단점 | 결정 |
|------------|------|------|------|
| **MongoDB** | 스키마 유연, 문서 지향, 샤딩 | 트랜잭션 제약(4.0+에서 개선), 조인 약함 | ✅ **선택** |
| **PostgreSQL** | 관계 무결성, ACID 완벽, JSON 지원 | 스키마 변경 번거로움, 수평 확장 제한 | ⏭ 대안 1 |
| **DynamoDB** | 서버리스, 확장성 우수, AWS 통합 | 쿼리 제약, 비용 예측 어려움, 로컬 개발 불편 | ❌ 제외 |
| **Neo4j** | 그래프 쿼리 최적화, 관계 탐색 우수 | 학습 곡선, 생태계 작음, 수평 확장 제약 | ❌ 제외 |

#### 트레이드오프
- **얻은 것**: 스키마 유연성, 빠른 개발, 수평 확장
- **포기한 것**: 관계형 무결성 자동 보장, 복잡한 조인
- **완화 전략**: 애플리케이션 레벨 참조 무결성 검증, 이벤트 소싱

#### 스키마 설계 예시
```javascript
// nodes 컬렉션
{
  _id: "node-123",
  conversationId: "conv-001",
  parentId: "node-122",
  role: "assistant",
  content: "...",
  depth: 3,
  meta: {
    tags: ["불안", "진로"],
    score: 0.85
  }
}
```

### 4.2 인덱스 전략

```javascript
// 경로 조회 최적화
db.nodes.createIndex({ conversationId: 1, parentId: 1, depth: 1 })

// 시간 기반 정렬
db.nodes.createIndex({ conversationId: 1, createdAt: -1 })

// 체크포인트 조회
db.checkpoints.createIndex({ conversationId: 1, createdAt: -1 })
```

## 5. 캐시 기술 선택

### 5.1 Redis

#### 선택 이유
1. **경로 캐싱**: `path:{nodeId}` → `[A, B, C]` (빠른 조회)
2. **LCA 결과 캐싱**: `lca:{nodeA}:{nodeB}` → `L` (계산 비용 절감)
3. **세션 관리**: 활성 경로, UI 상태 저장
4. **데이터 구조**: List, Set, Hash 등 다양한 자료구조 지원
5. **클러스터**: 수평 확장 가능

#### 대안 비교

| 기술 | 장점 | 단점 | 결정 |
|------|------|------|------|
| **Redis** | 빠름, 다양한 자료구조, 클러스터 지원 | 메모리 기반(영속성 제약), 복잡한 쿼리 불가 | ✅ **선택** |
| **Memcached** | 단순하고 빠름 | 자료구조 제한적, 영속성 없음 | ❌ 제외 |
| **In-Memory** | 설정 불필요 | 다중 인스턴스 불일치, 메모리 한계 | ⏭ 로컬 개발용 |

#### 캐시 전략
- **경로 캐시**: TTL 15분, 노드 생성/삭제 시 무효화
- **LCA 캐시**: TTL 15분, Write-Through
- **세션 캐시**: TTL 30분, Sliding Expiration

#### 예상 성능 개선
- 경로 조회: DB 50ms → 캐시 2ms (25배 향상)
- LCA 계산: 계산 30ms → 캐시 2ms (15배 향상)
- 캐시 적중률 목표: 80%

## 6. AI 통합 기술 선택

### 6.1 OpenAI API (GPT-4)

#### 선택 이유
1. **응답 품질**: 가장 높은 품질의 자연어 생성
2. **안정성**: 99.9% 가용성, 성숙한 서비스
3. **문서화**: 풍부한 문서, 활발한 커뮤니티
4. **기능**: Function calling, Streaming, Fine-tuning
5. **SDK**: 공식 Python SDK 제공

#### 대안 비교

| 프로바이더 | 장점 | 단점 | 결정 |
|-----------|------|------|------|
| **OpenAI GPT-4** | 최고 품질, 안정적, 풍부한 문서 | 비용 높음, API 호출 제약 | ✅ **선택** |
| **Anthropic Claude** | 긴 컨텍스트(100k), 안전성 우수 | OpenAI보다 생태계 작음 | ⏭ 대안 프로바이더 |
| **Google PaLM** | Google 통합, 다국어 강점 | 한국 서비스 제한, 문서 부족 | ❌ 제외 |
| **로컬 LLaMA** | 비용 제로, 데이터 보안 | 품질 낮음, 인프라 비용, 관리 부담 | ❌ 제외 |

#### 프로바이더 추상화 설계
```python
from abc import ABC, abstractmethod

class AIProvider(ABC):
    @abstractmethod
    async def generate(self, messages: list, max_tokens: int) -> str:
        pass

class OpenAIProvider(AIProvider):
    async def generate(self, messages: list, max_tokens: int) -> str:
        response = await openai.ChatCompletion.create(
            model="gpt-4",
            messages=messages,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content

class AnthropicProvider(AIProvider):
    async def generate(self, messages: list, max_tokens: int) -> str:
        # Anthropic Claude 구현
        pass
```

#### 비용 예상 (GPT-4 기준)
- 입력: $0.03 / 1K tokens
- 출력: $0.06 / 1K tokens
- 평균 대화: 입력 2K + 출력 500 토큰 = $0.09/대화
- 월 1,000 사용자 × 10 대화 = $900/월

#### 완화 전략
- GPT-3.5-turbo로 비용 절감 (1/10 가격)
- 프롬프트 최적화로 토큰 수 감소
- 캐싱으로 중복 호출 방지

## 7. 컨테이너 및 배포 기술 선택

### 7.1 Docker + Docker Compose

#### 선택 이유
1. **환경 일관성**: 로컬/스테이징/프로덕션 동일 환경
2. **의존성 격리**: Python, MongoDB, Redis 각각 컨테이너화
3. **개발 편의성**: `docker-compose up`으로 한 번에 실행
4. **이식성**: 어떤 환경에서도 동일하게 동작

#### docker-compose.yml 예시
```yaml
version: '3.8'
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    depends_on:
      - mongodb
      - redis
    environment:
      - MONGO_URL=mongodb://mongodb:27017
      - REDIS_URL=redis://redis:6379

  mongodb:
    image: mongo:6.0
    ports:
      - "27017:27017"
    volumes:
      - mongo_data:/data/db

  redis:
    image: redis:7.0
    ports:
      - "6379:6379"

volumes:
  mongo_data:
```

### 7.2 GitHub Actions (CI/CD)

#### 선택 이유
1. **무료**: Public 레포지토리 무료, Private도 월 2,000분 무료
2. **GitHub 통합**: PR, Issue와 자동 연동
3. **간편한 설정**: YAML 파일로 정의
4. **풍부한 Actions**: Docker, Python, 테스트 등 미리 제공

#### 대안 비교

| 도구 | 장점 | 단점 | 결정 |
|------|------|------|------|
| **GitHub Actions** | 무료, GitHub 통합, 간편 | GitHub 종속 | ✅ **선택** |
| **GitLab CI** | 강력한 기능, 자체 호스팅 가능 | GitLab 사용 필요 | ❌ 제외 |
| **Jenkins** | 매우 유연, 플러그인 풍부 | 설정 복잡, 서버 관리 필요 | ❌ 제외 |
| **CircleCI** | 빠른 빌드, 좋은 UX | 무료 제한, 비용 높음 | ❌ 제외 |

#### CI/CD 파이프라인
```yaml
# .github/workflows/backend-ci.yml
name: Backend CI
on: [push, pull_request]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      - run: pip install -r requirements.txt
      - run: pytest
      - run: docker build -t myapp:latest .
```

## 8. 기타 도구 및 라이브러리

### 8.1 Python 주요 라이브러리

| 라이브러리 | 용도 | 버전 | 선택 근거 |
|----------|------|------|----------|
| **FastAPI** | 웹 프레임워크 | 0.100+ | 비동기, 타입 힌트, 자동 문서화 |
| **Pydantic** | 데이터 검증 | 2.0+ | FastAPI 통합, 타입 안전 |
| **motor** | MongoDB 비동기 드라이버 | 3.0+ | asyncio 지원 |
| **redis-py** | Redis 클라이언트 | 5.0+ | 비동기 지원 |
| **openai** | OpenAI SDK | 1.0+ | 공식 SDK |
| **pydantic-settings** | 환경 설정 | 2.0+ | 타입 안전한 설정 관리 |
| **pytest** | 테스트 | 7.0+ | 파이썬 표준 테스트 도구 |
| **pytest-asyncio** | 비동기 테스트 | 0.21+ | asyncio 테스트 지원 |

### 8.2 프론트엔드 주요 라이브러리

| 라이브러리 | 용도 | 선택 근거 |
|----------|------|----------|
| **없음** | - | Vanilla JS로 시작, 필요 시 추가 |

### 8.3 개발 도구

| 도구 | 용도 | 선택 근거 |
|------|------|----------|
| **Black** | Python 코드 포매터 | 일관된 코드 스타일 |
| **Ruff** | Python 린터 | 빠르고 현대적 |
| **mypy** | 타입 체커 | 정적 타입 검증 |
| **pre-commit** | Git 훅 | 커밋 전 검증 자동화 |

## 9. 기술 선택 의사결정 트리

```
프론트엔드 선택
├─ 빠른 프로토타입 필요? → 예 → Vanilla JS ✅
└─ 대규모 앱? → 예 → React/Vue (2단계)

백엔드 언어 선택
├─ AI 통합 중요? → 예 → Python ✅
├─ 타입 안전 중요? → 예 → Java/Go (과도한 보일러플레이트)
└─ 성능 최우선? → 예 → Go/Rust (개발 속도 희생)

백엔드 프레임워크 선택
├─ 비동기 중요? → 예 → FastAPI ✅
├─ 성숙한 생태계? → 예 → Django (무겁고 동기)
└─ 가볍고 유연? → 예 → Flask (비동기 약함)

데이터베이스 선택
├─ 스키마 유연? → 예 → MongoDB ✅
├─ 관계 무결성? → 예 → PostgreSQL (스키마 변경 번거로움)
└─ 그래프 쿼리? → 예 → Neo4j (학습 곡선, 생태계)

캐시 선택
├─ 다양한 자료구조? → 예 → Redis ✅
└─ 단순 Key-Value? → 예 → Memcached (자료구조 제한)

AI 프로바이더 선택
├─ 최고 품질? → 예 → OpenAI GPT-4 ✅
├─ 긴 컨텍스트? → 예 → Anthropic Claude (대안)
└─ 비용 최소화? → 예 → 로컬 LLaMA (품질 희생)
```

## 10. 위험 및 완화 전략

### 10.1 성능 위험
- **위험**: Python GIL로 인한 멀티스레드 제약
- **완화**: asyncio 비동기 I/O로 동시성 확보, CPU 병목은 Cython 확장

### 10.2 확장성 위험
- **위험**: MongoDB 단일 인스턴스 용량 한계
- **완화**: 샤딩 준비, 인덱스 최적화, 캐시 적극 활용

### 10.3 비용 위험
- **위험**: OpenAI API 비용 증가
- **완화**: GPT-3.5-turbo 사용, 프롬프트 최적화, 캐싱

### 10.4 종속성 위험
- **위험**: OpenAI 장애 시 서비스 전체 중단
- **완화**: 프로바이더 추상화, Anthropic Claude 대안 준비, Circuit Breaker

## 11. 향후 기술 로드맵

### 1단계 (MVP)
- ✅ Python + FastAPI + MongoDB + Redis + OpenAI
- ✅ Vanilla JS 프론트엔드
- ✅ Docker + Docker Compose
- ✅ GitHub Actions CI/CD

### 2단계 (확장)
- React 프론트엔드 전환
- Anthropic Claude 프로바이더 추가
- Kubernetes 배포
- ELK 스택 로깅

### 3단계 (최적화)
- Binary Lifting 알고리즘 적용
- Cython 성능 최적화
- CDN 정적 파일 배포
- 다국어 지원

### 4단계 (고도화)
- GraphQL API 추가
- WebSocket 실시간 알림
- 모바일 앱 (React Native)
- Fine-tuning AI 모델

## 12. 결론

본 프로젝트는 **빠른 프로토타이핑과 AI 통합을 최우선**으로 하여 Python + FastAPI + MongoDB + OpenAI 스택을 선택했습니다. 프론트엔드는 Vanilla JS로 시작하여 알고리즘을 검증한 후 React로 전환하는 단계적 접근을 취합니다.

### 핵심 선택 근거 요약
1. **Python**: AI 라이브러리 풍부, 빠른 개발
2. **FastAPI**: 비동기, 타입 힌트, 자동 문서화
3. **MongoDB**: 스키마 유연성, 문서 지향
4. **Redis**: 경로 캐싱, 성능 향상
5. **OpenAI**: 최고 품질, 안정적 서비스
6. **Vanilla JS**: 빠른 프로토타입, 알고리즘 검증

### 주요 트레이드오프
- **성능 vs 개발 속도**: Python 선택 (개발 속도 우선)
- **스키마 유연성 vs 관계 무결성**: MongoDB 선택 (유연성 우선)
- **AI 품질 vs 비용**: OpenAI 선택 (품질 우선, 비용 최적화 병행)
- **프레임워크 vs 단순성**: Vanilla JS 선택 (단순성 우선, 향후 전환)

이 기술 스택은 MVP를 빠르게 구현하고, 향후 확장 및 최적화가 가능한 균형잡힌 선택입니다.
